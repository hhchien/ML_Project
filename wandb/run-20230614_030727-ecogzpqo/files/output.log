Training with WES datasets --- Window size = 16
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
219477 219477
(197529, 5, 33, 3) (197529, 3)
(21948, 5, 33, 3) (21948, 3)
(896, 5, 33, 3) (896, 3)
Balanced weights: [0.14904647 0.19026911 0.32735109]
Config: {'batch_size': 32, 'shuffle': True, 'num_workers': 3}
100
Training infor:
 - epoch: 100
 - Leanring rate: 0.001
 - Learning rate scheduler: True
 - Early stopping: False
[INFO] training the network...
[epoch: 1 -- Lr: [0.001] -- time: 28.460995197296143s]  --- Acc_train: 0.705587533982352 --- loss_train : 0.1012977307876947 --- Acc_val: 0.7494532531437944 --- loss_val : 0.09222889207536768
/media/data/huyennm/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
[epoch: 2 -- Lr: [0.001] -- time: 26.585203409194946s]  --- Acc_train: 0.7506340841091688 --- loss_train : 0.09103673390946199 --- Acc_val: 0.7550118461818844 --- loss_val : 0.08877181612064264
[epoch: 3 -- Lr: [0.001] -- time: 27.67583131790161s]  --- Acc_train: 0.7564003260280769 --- loss_train : 0.08925004897320601 --- Acc_val: 0.7491798797156917 --- loss_val : 0.08955064189061838
[epoch: 4 -- Lr: [0.001] -- time: 28.623132944107056s]  --- Acc_train: 0.7598377959691994 --- loss_train : 0.08822086135087788 --- Acc_val: 0.7609349371241115 --- loss_val : 0.08824150364861055
[epoch: 5 -- Lr: [0.001] -- time: 27.50666069984436s]  --- Acc_train: 0.761032557244759 --- loss_train : 0.08762209053514937 --- Acc_val: 0.762848551120831 --- loss_val : 0.08720646571283343
[epoch: 6 -- Lr: [0.001] -- time: 27.281471967697144s]  --- Acc_train: 0.762561446673653 --- loss_train : 0.0872477688193093 --- Acc_val: 0.762802988882814 --- loss_val : 0.08625837450276533
[epoch: 7 -- Lr: [0.001] -- time: 27.669987678527832s]  --- Acc_train: 0.7643637136825479 --- loss_train : 0.08687681597262094 --- Acc_val: 0.7686805175870238 --- loss_val : 0.08640570494025622
[epoch: 8 -- Lr: [0.001] -- time: 26.832047939300537s]  --- Acc_train: 0.7648750310081052 --- loss_train : 0.08657056005376457 --- Acc_val: 0.7651722252597047 --- loss_val : 0.08675883369851893
[epoch: 9 -- Lr: [0.001] -- time: 27.031168460845947s]  --- Acc_train: 0.7661811683347761 --- loss_train : 0.08631105589167049 --- Acc_val: 0.7589301986513578 --- loss_val : 0.08716401573892399
[epoch: 10 -- Lr: [0.001] -- time: 26.84374451637268s]  --- Acc_train: 0.7670316763614456 --- loss_train : 0.08590822916512961 --- Acc_val: 0.7627118644067796 --- loss_val : 0.08606166489871978
[epoch: 11 -- Lr: [0.001] -- time: 28.007036685943604s]  --- Acc_train: 0.766925362858112 --- loss_train : 0.08584773225965014 --- Acc_val: 0.7681337707308183 --- loss_val : 0.08804490161405487
[epoch: 12 -- Lr: [0.001] -- time: 26.183944702148438s]  --- Acc_train: 0.767441742731447 --- loss_train : 0.0854413052748771 --- Acc_val: 0.7705485693457262 --- loss_val : 0.0847245028182876
[epoch: 13 -- Lr: [0.001] -- time: 26.430057525634766s]  --- Acc_train: 0.7680391233692268 --- loss_train : 0.08523582721366343 --- Acc_val: 0.7634864224530709 --- loss_val : 0.08595436622428008
[epoch: 14 -- Lr: [0.001] -- time: 26.900389909744263s]  --- Acc_train: 0.7679581226047821 --- loss_train : 0.08525951202335047 --- Acc_val: 0.7699562602515035 --- loss_val : 0.08419693300442035
[epoch: 15 -- Lr: [0.001] -- time: 28.82491135597229s]  --- Acc_train: 0.7680492484647824 --- loss_train : 0.08496592331168051 --- Acc_val: 0.7674047749225442 --- loss_val : 0.08464020297462338
[epoch: 16 -- Lr: [0.001] -- time: 27.339336156845093s]  --- Acc_train: 0.7692693224792309 --- loss_train : 0.0847843225876065 --- Acc_val: 0.7690905777291781 --- loss_val : 0.08575516610890617
[epoch: 17 -- Lr: [0.001] -- time: 28.407495260238647s]  --- Acc_train: 0.7691579464281194 --- loss_train : 0.08468377307148879 --- Acc_val: 0.7660379077820303 --- loss_val : 0.08520992009924454
[epoch: 18 -- Lr: [0.001] -- time: 27.08647918701172s]  --- Acc_train: 0.7701907061747896 --- loss_train : 0.08430508129846119 --- Acc_val: 0.7484508839074175 --- loss_val : 0.08713304579433731
[epoch: 19 -- Lr: [0.001] -- time: 28.7989604473114s]  --- Acc_train: 0.7708083370036805 --- loss_train : 0.08429057260954047 --- Acc_val: 0.7675414616365955 --- loss_val : 0.08478164238981786
[epoch: 20 -- Lr: [0.001] -- time: 26.46236538887024s]  --- Acc_train: 0.7705400219714573 --- loss_train : 0.08422031231634505 --- Acc_val: 0.7703663203936577 --- loss_val : 0.08535705092706654
[epoch: 21 -- Lr: [0.001] -- time: 26.86696982383728s]  --- Acc_train: 0.7701957687225673 --- loss_train : 0.08418088768357936 --- Acc_val: 0.769455075633315 --- loss_val : 0.08442876862581632
[epoch: 22 -- Lr: [0.001] -- time: 28.223456621170044s]  --- Acc_train: 0.7707374613347914 --- loss_train : 0.08381050553323667 --- Acc_val: 0.7690450154911609 --- loss_val : 0.08405108699746464
[epoch: 23 -- Lr: [0.001] -- time: 27.17017364501953s]  --- Acc_train: 0.7714209052847937 --- loss_train : 0.08376899136361932 --- Acc_val: 0.7701385092035721 --- loss_val : 0.08392659740022122
[epoch: 24 -- Lr: [0.001] -- time: 27.06398892402649s]  --- Acc_train: 0.7712994041381266 --- loss_train : 0.08362264179305803 --- Acc_val: 0.7636686714051394 --- loss_val : 0.08553208165455732
[epoch: 25 -- Lr: [0.001] -- time: 26.718764305114746s]  --- Acc_train: 0.7709754010803477 --- loss_train : 0.08365671492773029 --- Acc_val: 0.7727355567705486 --- loss_val : 0.08369078207636255
[epoch: 26 -- Lr: [0.001] -- time: 26.384331226348877s]  --- Acc_train: 0.772225850381463 --- loss_train : 0.08353894282575279 --- Acc_val: 0.7711864406779662 --- loss_val : 0.0831878607009769
[epoch: 27 -- Lr: [0.001] -- time: 26.763962745666504s]  --- Acc_train: 0.771881597132573 --- loss_train : 0.08330736177153017 --- Acc_val: 0.759340258793512 --- loss_val : 0.08602074227708932
[epoch: 28 -- Lr: [0.001] -- time: 27.09986925125122s]  --- Acc_train: 0.7712538412081265 --- loss_train : 0.08311225738814806 --- Acc_val: 0.7712320029159833 --- loss_val : 0.0838603135626099
[epoch: 29 -- Lr: [0.001] -- time: 26.546462774276733s]  --- Acc_train: 0.7723321638847966 --- loss_train : 0.08314685770270797 --- Acc_val: 0.7716420630581374 --- loss_val : 0.08400739498932766
[epoch: 30 -- Lr: [0.001] -- time: 27.45726442337036s]  --- Acc_train: 0.7721094117825738 --- loss_train : 0.08303770947976633 --- Acc_val: 0.7679515217787498 --- loss_val : 0.0835198647020877
[epoch: 31 -- Lr: [0.001] -- time: 26.605376958847046s]  --- Acc_train: 0.772620729108131 --- loss_train : 0.08281961842018731 --- Acc_val: 0.7508201202843083 --- loss_val : 0.0895083715192453
[epoch: 32 -- Lr: [0.0009000000000000001] -- time: 28.120239973068237s]  --- Acc_train: 0.7732181097459108 --- loss_train : 0.0825843392422524 --- Acc_val: 0.7758793511937306 --- loss_val : 0.08268733938018198
[epoch: 33 -- Lr: [0.0008100000000000001] -- time: 27.70157527923584s]  --- Acc_train: 0.7747267489836935 --- loss_train : 0.08226321272222885 --- Acc_val: 0.7713686896300346 --- loss_val : 0.08443262934289845
[epoch: 34 -- Lr: [0.0007290000000000002] -- time: 26.42091965675354s]  --- Acc_train: 0.7743622455436924 --- loss_train : 0.08203478046036519 --- Acc_val: 0.7737834882449426 --- loss_val : 0.08532729882152174
[epoch: 35 -- Lr: [0.0006561000000000001] -- time: 28.2235004901886s]  --- Acc_train: 0.7749950640159167 --- loss_train : 0.08171938739379632 --- Acc_val: 0.7741024239110625 --- loss_val : 0.08262570093086877
[epoch: 36 -- Lr: [0.00059049] -- time: 26.934736967086792s]  --- Acc_train: 0.7759265728070308 --- loss_train : 0.0813171887111453 --- Acc_val: 0.7699562602515035 --- loss_val : 0.08347602382671337
[epoch: 37 -- Lr: [0.000531441] -- time: 26.695451259613037s]  --- Acc_train: 0.77634170172481 --- loss_train : 0.08115146867660777 --- Acc_val: 0.7755148532895936 --- loss_val : 0.08191969020167986
[epoch: 38 -- Lr: [0.0004782969000000001] -- time: 27.16989254951477s]  --- Acc_train: 0.7760784492403647 --- loss_train : 0.08099841951804389 --- Acc_val: 0.7748769819573538 --- loss_val : 0.08239993102307369
[epoch: 39 -- Lr: [0.0004304672100000001] -- time: 27.67514157295227s]  --- Acc_train: 0.7767467055470336 --- loss_train : 0.08077150326662903 --- Acc_val: 0.7720521232002916 --- loss_val : 0.08252189229831179
[epoch: 40 -- Lr: [0.0003874204890000001] -- time: 26.59908127784729s]  --- Acc_train: 0.7778655286059262 --- loss_train : 0.0805561062434349 --- Acc_val: 0.7748314197193367 --- loss_val : 0.08173412426485761
[epoch: 41 -- Lr: [0.0003486784401000001] -- time: 26.463782787322998s]  --- Acc_train: 0.7783009077148165 --- loss_train : 0.0802944686431754 --- Acc_val: 0.7754692910515765 --- loss_val : 0.0818009879781261
[epoch: 42 -- Lr: [0.0003138105960900001] -- time: 26.4270601272583s]  --- Acc_train: 0.7779870297525933 --- loss_train : 0.08035132946955865 --- Acc_val: 0.7752870420995079 --- loss_val : 0.08150019769735845
[epoch: 43 -- Lr: [0.0002824295364810001] -- time: 26.477135181427002s]  --- Acc_train: 0.7783211579059277 --- loss_train : 0.08001872928601657 --- Acc_val: 0.777382905048296 --- loss_val : 0.08217300321409989
[epoch: 44 -- Lr: [0.0002541865828329001] -- time: 27.06032633781433s]  --- Acc_train: 0.7788375377792628 --- loss_train : 0.07992576625780677 --- Acc_val: 0.7734645525788226 --- loss_val : 0.08189700520020544
[epoch: 45 -- Lr: [0.0002287679245496101] -- time: 26.504016160964966s]  --- Acc_train: 0.7788223501359294 --- loss_train : 0.07990710328096616 --- Acc_val: 0.7751047931474394 --- loss_val : 0.0813187658091205
[epoch: 46 -- Lr: [0.0002058911320946491] -- time: 26.43561363220215s]  --- Acc_train: 0.7788223501359294 --- loss_train : 0.0797561286810333 --- Acc_val: 0.7776562784763987 --- loss_val : 0.0810338069801782
[epoch: 47 -- Lr: [0.00018530201888518417] -- time: 26.575997352600098s]  --- Acc_train: 0.7787362868237069 --- loss_train : 0.07956247698182113 --- Acc_val: 0.7756971022416621 --- loss_val : 0.08137227087450463
[epoch: 48 -- Lr: [0.00016677181699666576] -- time: 27.344239711761475s]  --- Acc_train: 0.7799917986725999 --- loss_train : 0.07958067732613161 --- Acc_val: 0.7756059777656279 --- loss_val : 0.0811915356321111
[epoch: 49 -- Lr: [0.00015009463529699917] -- time: 28.57495427131653s]  --- Acc_train: 0.7800424241503779 --- loss_train : 0.07945915495776652 --- Acc_val: 0.7771550938582104 --- loss_val : 0.08125269845716496
[epoch: 50 -- Lr: [0.0001350851717672993] -- time: 28.222904443740845s]  --- Acc_train: 0.7800322990548223 --- loss_train : 0.07936636946432025 --- Acc_val: 0.7769728449061418 --- loss_val : 0.0811182357065221
[epoch: 51 -- Lr: [0.00012157665459056935] -- time: 27.09291911125183s]  --- Acc_train: 0.7805233661892684 --- loss_train : 0.07922585106775859 --- Acc_val: 0.7728722434845999 --- loss_val : 0.08172978011001954
[epoch: 52 -- Lr: [0.00010941898913151242] -- time: 26.908333778381348s]  --- Acc_train: 0.7792982296270421 --- loss_train : 0.07924162466196034 --- Acc_val: 0.7762894113358848 --- loss_val : 0.08106951335883775
[epoch: 53 -- Lr: [9.847709021836118e-05] -- time: 27.033429861068726s]  --- Acc_train: 0.7793134172703755 --- loss_train : 0.07925515833111144 --- Acc_val: 0.777063969382176 --- loss_val : 0.08105728250890745
[epoch: 54 -- Lr: [8.862938119652506e-05] -- time: 27.29475450515747s]  --- Acc_train: 0.7808828070814918 --- loss_train : 0.0791325513974076 --- Acc_val: 0.7761071623838163 --- loss_val : 0.08107795044869441
[epoch: 55 -- Lr: [7.976644307687256e-05] -- time: 26.459698915481567s]  --- Acc_train: 0.7810701213492702 --- loss_train : 0.07902139885848833 --- Acc_val: 0.7787497721888099 --- loss_val : 0.08107481681145347
[epoch: 56 -- Lr: [7.17897987691853e-05] -- time: 26.77836799621582s]  --- Acc_train: 0.7803411144692678 --- loss_train : 0.07912488406065682 --- Acc_val: 0.7766539092400219 --- loss_val : 0.08099728498088493
[epoch: 57 -- Lr: [6.461081889226677e-05] -- time: 26.860738277435303s]  --- Acc_train: 0.7809891205848255 --- loss_train : 0.0789180350048351 --- Acc_val: 0.7782485875706214 --- loss_val : 0.08119492199169101
[epoch: 58 -- Lr: [5.8149737003040094e-05] -- time: 28.89432954788208s]  --- Acc_train: 0.780584116762602 --- loss_train : 0.0789766209350829 --- Acc_val: 0.7768361581920904 --- loss_val : 0.08112141600307929
[epoch: 59 -- Lr: [5.233476330273609e-05] -- time: 26.53148865699768s]  --- Acc_train: 0.7818345660637173 --- loss_train : 0.07879485818572378 --- Acc_val: 0.7761527246218334 --- loss_val : 0.081070679776769
[epoch: 60 -- Lr: [4.7101286972462485e-05] -- time: 29.691844940185547s]  --- Acc_train: 0.7818244409681616 --- loss_train : 0.07886204447188094 --- Acc_val: 0.7765172225259704 --- loss_val : 0.08100137580011796
[epoch: 61 -- Lr: [4.239115827521624e-05] -- time: 26.48147416114807s]  --- Acc_train: 0.7808068688648249 --- loss_train : 0.07873708699232698 --- Acc_val: 0.7783397120466558 --- loss_val : 0.08095839646415944
[epoch: 62 -- Lr: [3.8152042447694614e-05] -- time: 26.91405963897705s]  --- Acc_train: 0.7811409970181593 --- loss_train : 0.07882707722934407 --- Acc_val: 0.7767905959540733 --- loss_val : 0.08102602483909935
[epoch: 63 -- Lr: [3.433683820292515e-05] -- time: 28.50187373161316s]  --- Acc_train: 0.7810346835148256 --- loss_train : 0.07876656385058378 --- Acc_val: 0.7772006560962275 --- loss_val : 0.08096193488338621
[epoch: 64 -- Lr: [3.090315438263264e-05] -- time: 28.538284301757812s]  --- Acc_train: 0.7819763174014954 --- loss_train : 0.07875356348458708 --- Acc_val: 0.7756059777656279 --- loss_val : 0.08119044039107087
[epoch: 65 -- Lr: [2.7812838944369376e-05] -- time: 27.19422149658203s]  --- Acc_train: 0.7813181861903822 --- loss_train : 0.07876835632220887 --- Acc_val: 0.7760160379077821 --- loss_val : 0.08129232557522043
[epoch: 66 -- Lr: [2.5031555049932436e-05] -- time: 26.53426170349121s]  --- Acc_train: 0.781789003133717 --- loss_train : 0.07870702616741294 --- Acc_val: 0.7769728449061418 --- loss_val : 0.08097605571779559
[epoch: 67 -- Lr: [2.2528399544939195e-05] -- time: 26.74282717704773s]  --- Acc_train: 0.7816877521781612 --- loss_train : 0.07867560408917848 --- Acc_val: 0.7754237288135594 --- loss_val : 0.08102379577716017
[epoch: 68 -- Lr: [2.0275559590445276e-05] -- time: 26.44563055038452s]  --- Acc_train: 0.7805891793103797 --- loss_train : 0.07868060920049932 --- Acc_val: 0.7776107162383816 --- loss_val : 0.08099895157625853
[epoch: 69 -- Lr: [1.824800363140075e-05] -- time: 26.994033575057983s]  --- Acc_train: 0.7819712548537177 --- loss_train : 0.07866545318611119 --- Acc_val: 0.7774284672863131 --- loss_val : 0.08097952297027747
[epoch: 70 -- Lr: [1.6423203268260675e-05] -- time: 26.922419786453247s]  --- Acc_train: 0.7806904302659357 --- loss_train : 0.07871222171061279 --- Acc_val: 0.7761071623838163 --- loss_val : 0.0809664848777749
[epoch: 71 -- Lr: [1.4780882941434608e-05] -- time: 27.638405561447144s]  --- Acc_train: 0.7805537414759351 --- loss_train : 0.07871038475162433 --- Acc_val: 0.7768817204301075 --- loss_val : 0.0809293967897156
[epoch: 72 -- Lr: [1.3302794647291146e-05] -- time: 26.538492918014526s]  --- Acc_train: 0.7814093120503824 --- loss_train : 0.07867494058121124 --- Acc_val: 0.7782941498086386 --- loss_val : 0.08091061950772421
[epoch: 73 -- Lr: [1.1972515182562033e-05] -- time: 29.53564453125s]  --- Acc_train: 0.781520688101494 --- loss_train : 0.07866011510965444 --- Acc_val: 0.7759704756697648 --- loss_val : 0.08105913435352498
[epoch: 74 -- Lr: [1.077526366430583e-05] -- time: 29.497910976409912s]  --- Acc_train: 0.780903057272603 --- loss_train : 0.07865296067343099 --- Acc_val: 0.7762438490978677 --- loss_val : 0.08097448252979739
[epoch: 75 -- Lr: [9.697737297875246e-06] -- time: 27.823729991912842s]  --- Acc_train: 0.7815308131970495 --- loss_train : 0.07871686884269524 --- Acc_val: 0.7779752141425187 --- loss_val : 0.08089329811636536
[epoch: 76 -- Lr: [8.727963568087722e-06] -- time: 28.035069227218628s]  --- Acc_train: 0.7823458833892745 --- loss_train : 0.078575882382604 --- Acc_val: 0.7763349735739019 --- loss_val : 0.08101855840758455
[epoch: 77 -- Lr: [7.85516721127895e-06] -- time: 26.69457197189331s]  --- Acc_train: 0.7815713135792719 --- loss_train : 0.07862569887901273 --- Acc_val: 0.7761982868598506 --- loss_val : 0.08109732129373286
[epoch: 78 -- Lr: [7.069650490151056e-06] -- time: 27.426992416381836s]  --- Acc_train: 0.7811308719226038 --- loss_train : 0.07872682265275543 --- Acc_val: 0.7774284672863131 --- loss_val : 0.0809277203604365
[epoch: 79 -- Lr: [6.36268544113595e-06] -- time: 27.511972427368164s]  --- Acc_train: 0.7808777445337141 --- loss_train : 0.07867215260080727 --- Acc_val: 0.7764260980499362 --- loss_val : 0.0810614690907268
[epoch: 80 -- Lr: [5.726416897022355e-06] -- time: 27.834176301956177s]  --- Acc_train: 0.7819864424970511 --- loss_train : 0.07872394273418722 --- Acc_val: 0.7784763987607072 --- loss_val : 0.08096688387627725
[epoch: 81 -- Lr: [5.15377520732012e-06] -- time: 27.724738121032715s]  --- Acc_train: 0.781616876509272 --- loss_train : 0.07862944947959731 --- Acc_val: 0.7761982868598506 --- loss_val : 0.08094472092197619
[epoch: 82 -- Lr: [4.638397686588108e-06] -- time: 29.07741403579712s]  --- Acc_train: 0.7815358757448273 --- loss_train : 0.07861456957200866 --- Acc_val: 0.7762438490978677 --- loss_val : 0.08103431499703781
[epoch: 83 -- Lr: [4.174557917929297e-06] -- time: 26.438422441482544s]  --- Acc_train: 0.7818902540892729 --- loss_train : 0.07859065303064508 --- Acc_val: 0.7757882267176964 --- loss_val : 0.0809872801182653
[epoch: 84 -- Lr: [3.7571021261363675e-06] -- time: 28.09959864616394s]  --- Acc_train: 0.7814244996937159 --- loss_train : 0.07857776232838502 --- Acc_val: 0.7762894113358848 --- loss_val : 0.08099527759049714
[epoch: 85 -- Lr: [3.381391913522731e-06] -- time: 28.157620191574097s]  --- Acc_train: 0.7813131236426044 --- loss_train : 0.07859392237308428 --- Acc_val: 0.7751503553854565 --- loss_val : 0.08103054235934079
[epoch: 86 -- Lr: [3.0432527221704577e-06] -- time: 29.692733764648438s]  --- Acc_train: 0.7810650588014925 --- loss_train : 0.07853952772341016 --- Acc_val: 0.7769272826681246 --- loss_val : 0.08102717693614953
[epoch: 87 -- Lr: [2.7389274499534123e-06] -- time: 28.50768733024597s]  --- Acc_train: 0.7807866186737137 --- loss_train : 0.07870373371769686 --- Acc_val: 0.7749225441953709 --- loss_val : 0.08111534920233462
[epoch: 88 -- Lr: [2.465034704958071e-06] -- time: 27.369210958480835s]  --- Acc_train: 0.7812675607126042 --- loss_train : 0.07852722353311481 --- Acc_val: 0.7764260980499362 --- loss_val : 0.0810172706707556
[epoch: 89 -- Lr: [2.218531234462264e-06] -- time: 28.64527726173401s]  --- Acc_train: 0.7814801877192716 --- loss_train : 0.07857720895107637 --- Acc_val: 0.7786130854747585 --- loss_val : 0.08090096036702395
[epoch: 90 -- Lr: [1.9966781110160375e-06] -- time: 27.691335678100586s]  --- Acc_train: 0.7811612472092705 --- loss_train : 0.0787219493598551 --- Acc_val: 0.7781574630945872 --- loss_val : 0.0809596999775895
[epoch: 91 -- Lr: [1.797010299914434e-06] -- time: 27.983229398727417s]  --- Acc_train: 0.7814093120503824 --- loss_train : 0.07849587034689996 --- Acc_val: 0.7775651540003645 --- loss_val : 0.08095602384322319
[epoch: 92 -- Lr: [1.6173092699229906e-06] -- time: 27.814836263656616s]  --- Acc_train: 0.7818295035159394 --- loss_train : 0.07862349884535434 --- Acc_val: 0.7775651540003645 --- loss_val : 0.08095940444384662
[epoch: 93 -- Lr: [1.4555783429306915e-06] -- time: 28.21908473968506s]  --- Acc_train: 0.7819864424970511 --- loss_train : 0.07865724468348098 --- Acc_val: 0.7779296519045016 --- loss_val : 0.08092477777924578
[epoch: 94 -- Lr: [1.3100205086376223e-06] -- time: 26.875087022781372s]  --- Acc_train: 0.7812827483559376 --- loss_train : 0.07862983713745701 --- Acc_val: 0.7762438490978677 --- loss_val : 0.08097385276598053
[epoch: 95 -- Lr: [1.1790184577738603e-06] -- time: 29.234717845916748s]  --- Acc_train: 0.7816219390570498 --- loss_train : 0.07854889580223635 --- Acc_val: 0.7761982868598506 --- loss_val : 0.0809444723319521
[epoch: 96 -- Lr: [1.061116611996474e-06] -- time: 28.245930433273315s]  --- Acc_train: 0.781546000840383 --- loss_train : 0.07854751988727109 --- Acc_val: 0.7757426644796792 --- loss_val : 0.08101902905416274
[epoch: 97 -- Lr: [9.550049507968267e-07] -- time: 28.044530153274536s]  --- Acc_train: 0.7811865599481596 --- loss_train : 0.07859946099813318 --- Acc_val: 0.7762894113358848 --- loss_val : 0.08099498681769728
[epoch: 98 -- Lr: [8.595044557171441e-07] -- time: 27.385435104370117s]  --- Acc_train: 0.7819763174014954 --- loss_train : 0.07846712590002564 --- Acc_val: 0.7775651540003645 --- loss_val : 0.08091875432560922
[epoch: 99 -- Lr: [7.735540101454298e-07] -- time: 27.537081480026245s]  --- Acc_train: 0.781470062623716 --- loss_train : 0.07868998374437824 --- Acc_val: 0.7781119008565701 --- loss_val : 0.08092587693162792
[epoch: 100 -- Lr: [6.961986091308867e-07] -- time: 29.228761672973633s]  --- Acc_train: 0.7816016888659387 --- loss_train : 0.07863494722862253 --- Acc_val: 0.777063969382176 --- loss_val : 0.08093147128940423