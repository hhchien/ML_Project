/media/data/huyennm/ML/training_wes_copy.py:1: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives
  from distutils.command.config import config
wandb: Currently logged in as: mnhhuyen-26 (huyennm). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /media/data/huyennm/ML/wandb/run-20230614_045652-pe3y8dwj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run WES_ws_16
wandb: ‚≠êÔ∏è View project at https://wandb.ai/huyennm/Mutation_Detection_With_CNN%20
wandb: üöÄ View run at https://wandb.ai/huyennm/Mutation_Detection_With_CNN%20/runs/pe3y8dwj
Training with WES datasets --- Window size = 16
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]
219477 219477
(197529, 5, 33, 3) (197529, 3)
(21948, 5, 33, 3) (21948, 3)
(896, 5, 33, 3) (896, 3)
Balanced weights: [0.14904647 0.19026911 0.32735109]
Config: {'batch_size': 32, 'shuffle': True, 'num_workers': 3}
100
Training infor:
 - epoch: 100 
 - Leanring rate: 0.001 
 - Learning rate scheduler: True 
 - Early stopping: False 

[INFO] training the network...
/media/data/huyennm/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
[epoch: 1 -- Lr: [0.001] -- time: 27.949456453323364s]  --- Acc_train: 0.718086964445727 --- loss_train : 0.10058363396832148 --- Acc_val: 0.7538727902314561 --- loss_val : 0.09120837469554222 --- f1_score: 0.7544502171738058
[epoch: 2 -- Lr: [0.001] -- time: 27.120046377182007s]  --- Acc_train: 0.7485128765902728 --- loss_train : 0.09147703546323664 --- Acc_val: 0.7469017678148351 --- loss_val : 0.09286854741444307 --- f1_score: 0.7480002251310728
[epoch: 3 -- Lr: [0.001] -- time: 27.56958317756653s]  --- Acc_train: 0.7545879339236264 --- loss_train : 0.08977139584256386 --- Acc_val: 0.7568798979405869 --- loss_val : 0.08754298945331467 --- f1_score: 0.7579763215296583
[epoch: 4 -- Lr: [0.001] -- time: 26.6670081615448s]  --- Acc_train: 0.7569065808058564 --- loss_train : 0.08839212981276812 --- Acc_val: 0.7643521049753964 --- loss_val : 0.08778120264730213 --- f1_score: 0.7642174368266883
[epoch: 5 -- Lr: [0.001] -- time: 26.644869565963745s]  --- Acc_train: 0.7600605480714224 --- loss_train : 0.08761434350395914 --- Acc_val: 0.7639876070712593 --- loss_val : 0.08602970328477762 --- f1_score: 0.7647103731615824
[epoch: 6 -- Lr: [0.001] -- time: 26.841829299926758s]  --- Acc_train: 0.7614932490925383 --- loss_train : 0.08684964925819962 --- Acc_val: 0.7627118644067796 --- loss_val : 0.08605242907503761 --- f1_score: 0.7634305853286576
[epoch: 7 -- Lr: [0.001] -- time: 26.51030659675598s]  --- Acc_train: 0.76367014463699 --- loss_train : 0.08628466340420657 --- Acc_val: 0.7642609804993621 --- loss_val : 0.08562452654817086 --- f1_score: 0.765017055908011
[epoch: 8 -- Lr: [0.001] -- time: 26.76078152656555s]  --- Acc_train: 0.7641865245103251 --- loss_train : 0.08596117965058674 --- Acc_val: 0.7650811007836705 --- loss_val : 0.08459568328639466 --- f1_score: 0.7658434935318179
[epoch: 9 -- Lr: [0.001] -- time: 27.241870164871216s]  --- Acc_train: 0.7649104688425497 --- loss_train : 0.08552122256935944 --- Acc_val: 0.7698651357754693 --- loss_val : 0.08451658279465685 --- f1_score: 0.7703627684375143
[epoch: 10 -- Lr: [0.001] -- time: 26.479079961776733s]  --- Acc_train: 0.7658571652769973 --- loss_train : 0.08530171321882614 --- Acc_val: 0.7730544924366685 --- loss_val : 0.08460117750689526 --- f1_score: 0.7732849421475617
[epoch: 11 -- Lr: [0.001] -- time: 26.430416107177734s]  --- Acc_train: 0.7675227434958918 --- loss_train : 0.08485704033136382 --- Acc_val: 0.7713686896300346 --- loss_val : 0.08414731977490342 --- f1_score: 0.7720356076367855
[epoch: 12 -- Lr: [0.001] -- time: 28.565186738967896s]  --- Acc_train: 0.7679125596747819 --- loss_train : 0.08456803064456704 --- Acc_val: 0.7685893931109896 --- loss_val : 0.08425697471382328 --- f1_score: 0.7691742806772495
[epoch: 13 -- Lr: [0.001] -- time: 29.559310913085938s]  --- Acc_train: 0.7680543110125602 --- loss_train : 0.08434410725760984 --- Acc_val: 0.7708219427738291 --- loss_val : 0.08365165396888488 --- f1_score: 0.7716503145243584
[epoch: 14 -- Lr: [0.001] -- time: 28.313008308410645s]  --- Acc_train: 0.7691022584025636 --- loss_train : 0.0842366522537616 --- Acc_val: 0.7688172043010753 --- loss_val : 0.08406702981644947 --- f1_score: 0.7694897472783917
[epoch: 15 -- Lr: [0.001] -- time: 27.20111322402954s]  --- Acc_train: 0.7691225085936748 --- loss_train : 0.08411809225830258 --- Acc_val: 0.7769728449061418 --- loss_val : 0.08446366662754122 --- f1_score: 0.7767482455926574
[epoch: 16 -- Lr: [0.001] -- time: 27.598178386688232s]  --- Acc_train: 0.7703172698692344 --- loss_train : 0.08374227758294552 --- Acc_val: 0.7670402770184072 --- loss_val : 0.08331159965405698 --- f1_score: 0.7679103139040103
[epoch: 17 -- Lr: [0.001] -- time: 29.79869818687439s]  --- Acc_train: 0.7709298381503475 --- loss_train : 0.08371805430783577 --- Acc_val: 0.7741479861490796 --- loss_val : 0.08344486401567862 --- f1_score: 0.7747198010599055
[epoch: 18 -- Lr: [0.001] -- time: 27.880411863327026s]  --- Acc_train: 0.7714057176414603 --- loss_train : 0.08359622669635915 --- Acc_val: 0.7760160379077821 --- loss_val : 0.0833478956356924 --- f1_score: 0.7763950206508494
[epoch: 19 -- Lr: [0.001] -- time: 28.618553400039673s]  --- Acc_train: 0.7709399632459031 --- loss_train : 0.08344850924208208 --- Acc_val: 0.7736468015308912 --- loss_val : 0.0825956311413571 --- f1_score: 0.7743527417994059
[epoch: 20 -- Lr: [0.001] -- time: 26.90701723098755s]  --- Acc_train: 0.7714057176414603 --- loss_train : 0.08327170255758737 --- Acc_val: 0.7788864589028613 --- loss_val : 0.08324254961321136 --- f1_score: 0.77891744524942
[epoch: 21 -- Lr: [0.001] -- time: 27.081340551376343s]  --- Acc_train: 0.7715322813359051 --- loss_train : 0.0833410349094619 --- Acc_val: 0.7686805175870238 --- loss_val : 0.08352292475784326 --- f1_score: 0.769483442992186
[epoch: 22 -- Lr: [0.001] -- time: 26.627302169799805s]  --- Acc_train: 0.7722359754770186 --- loss_train : 0.08297675982969703 --- Acc_val: 0.7745124840532167 --- loss_val : 0.08275843491929648 --- f1_score: 0.7751539800344983
[epoch: 23 -- Lr: [0.001] -- time: 27.93440866470337s]  --- Acc_train: 0.7726055414647975 --- loss_train : 0.08291865406930264 --- Acc_val: 0.7685438308729725 --- loss_val : 0.08363100075232895 --- f1_score: 0.7693189238982157
[epoch: 24 -- Lr: [0.001] -- time: 27.48482894897461s]  --- Acc_train: 0.7728941066881319 --- loss_train : 0.08276283361158501 --- Acc_val: 0.7778840896664844 --- loss_val : 0.08294721545955475 --- f1_score: 0.7783362948501282
[epoch: 25 -- Lr: [0.001] -- time: 26.627092838287354s]  --- Acc_train: 0.773015607834799 --- loss_train : 0.08270810521222116 --- Acc_val: 0.7761982868598506 --- loss_val : 0.08292315006259199 --- f1_score: 0.7768109513614012
[epoch: 26 -- Lr: [0.001] -- time: 28.34335231781006s]  --- Acc_train: 0.772372664267019 --- loss_train : 0.08279339869721651 --- Acc_val: 0.7729633679606343 --- loss_val : 0.08216823494063165 --- f1_score: 0.7737957762184245
[epoch: 27 -- Lr: [0.001] -- time: 27.57603883743286s]  --- Acc_train: 0.7737344896192457 --- loss_train : 0.08249520959662122 --- Acc_val: 0.7746036085292509 --- loss_val : 0.0827731903585519 --- f1_score: 0.7749610030809718
[epoch: 28 -- Lr: [0.001] -- time: 27.558287143707275s]  --- Acc_train: 0.7733142981536888 --- loss_train : 0.08247471006705667 --- Acc_val: 0.7722343721523601 --- loss_val : 0.08245378384851428 --- f1_score: 0.7731325689636784
[epoch: 29 -- Lr: [0.001] -- time: 26.756935596466064s]  --- Acc_train: 0.7748533126781384 --- loss_train : 0.08240478368026816 --- Acc_val: 0.7734189903408055 --- loss_val : 0.08196091403267862 --- f1_score: 0.7745892499120778
[epoch: 30 -- Lr: [0.001] -- time: 27.39450240135193s]  --- Acc_train: 0.7747166238881379 --- loss_train : 0.08225309704023073 --- Acc_val: 0.777063969382176 --- loss_val : 0.08255670316898386 --- f1_score: 0.7776337858506758
[epoch: 31 -- Lr: [0.001] -- time: 27.399113416671753s]  --- Acc_train: 0.7739774919125799 --- loss_train : 0.08228180315925909 --- Acc_val: 0.7763805358119191 --- loss_val : 0.08259259227866435 --- f1_score: 0.7770951362722464
[epoch: 32 -- Lr: [0.0009000000000000001] -- time: 27.58638286590576s]  --- Acc_train: 0.774271119683692 --- loss_train : 0.08196464272718083 --- Acc_val: 0.7712320029159833 --- loss_val : 0.08196275451737914 --- f1_score: 0.7721965650860599
[epoch: 33 -- Lr: [0.0008100000000000001] -- time: 28.27243208885193s]  --- Acc_train: 0.7755114438892518 --- loss_train : 0.08152748342158103 --- Acc_val: 0.7762894113358848 --- loss_val : 0.08161473230867579 --- f1_score: 0.7769815875568498
[epoch: 34 -- Lr: [0.0007290000000000002] -- time: 27.76205539703369s]  --- Acc_train: 0.7768580815981451 --- loss_train : 0.08126710588714159 --- Acc_val: 0.7761527246218334 --- loss_val : 0.08102566360444727 --- f1_score: 0.7770189671312194
[epoch: 35 -- Lr: [0.0006561000000000001] -- time: 28.295883893966675s]  --- Acc_train: 0.7777541525548147 --- loss_train : 0.08107586745345893 --- Acc_val: 0.7782030253326043 --- loss_val : 0.0815499385993339 --- f1_score: 0.7788814531128966
[epoch: 36 -- Lr: [0.00059049] -- time: 28.92902374267578s]  --- Acc_train: 0.777845278414815 --- loss_train : 0.08074494326083996 --- Acc_val: 0.7800710770913067 --- loss_val : 0.08108076281232764 --- f1_score: 0.7804513582361886
[epoch: 37 -- Lr: [0.000531441] -- time: 26.88664722442627s]  --- Acc_train: 0.7784224088614836 --- loss_train : 0.08052280159372471 --- Acc_val: 0.7794332057590669 --- loss_val : 0.0808503036211644 --- f1_score: 0.7800607207433465
[epoch: 38 -- Lr: [0.0004782969000000001] -- time: 26.958553791046143s]  --- Acc_train: 0.7793083547225977 --- loss_train : 0.08029455911833931 --- Acc_val: 0.7790687078549299 --- loss_val : 0.0813141371477888 --- f1_score: 0.7796965783926064
[epoch: 39 -- Lr: [0.0004304672100000001] -- time: 26.586774110794067s]  --- Acc_train: 0.7788982883525963 --- loss_train : 0.08011347873024846 --- Acc_val: 0.7747402952433023 --- loss_val : 0.08110128789161984 --- f1_score: 0.7754702718480474
[epoch: 40 -- Lr: [0.0003874204890000001] -- time: 27.561378002166748s]  --- Acc_train: 0.7792121663148196 --- loss_train : 0.07985193512452046 --- Acc_val: 0.7796610169491526 --- loss_val : 0.08083311678733193 --- f1_score: 0.7803877893804818
[epoch: 41 -- Lr: [0.0003486784401000001] -- time: 26.967769384384155s]  --- Acc_train: 0.7803512395648234 --- loss_train : 0.07969538727166921 --- Acc_val: 0.7774740295243302 --- loss_val : 0.08043493864647212 --- f1_score: 0.7783120051753082
[epoch: 42 -- Lr: [0.0003138105960900001] -- time: 27.258047580718994s]  --- Acc_train: 0.7797741091181548 --- loss_train : 0.07944240410154058 --- Acc_val: 0.7746036085292509 --- loss_val : 0.08097877801648712 --- f1_score: 0.7756136413265435
[epoch: 43 -- Lr: [0.0002824295364810001] -- time: 29.37371850013733s]  --- Acc_train: 0.781642189248161 --- loss_train : 0.0793848820670165 --- Acc_val: 0.780526699471478 --- loss_val : 0.08044634234259755 --- f1_score: 0.7811988029034607
[epoch: 44 -- Lr: [0.0002541865828329001] -- time: 28.133272886276245s]  --- Acc_train: 0.781789003133717 --- loss_train : 0.07927639234035724 --- Acc_val: 0.7794332057590669 --- loss_val : 0.08025728272787731 --- f1_score: 0.7800961010046595
[epoch: 45 -- Lr: [0.0002287679245496101] -- time: 27.368390560150146s]  --- Acc_train: 0.7806296796926021 --- loss_train : 0.07916160095922921 --- Acc_val: 0.7804811372334609 --- loss_val : 0.08011817484349898 --- f1_score: 0.781113093453824
[epoch: 46 -- Lr: [0.0002058911320946491] -- time: 26.464359521865845s]  --- Acc_train: 0.7814801877192716 --- loss_train : 0.07908595644504922 --- Acc_val: 0.777747402952433 --- loss_val : 0.08047645260256467 --- f1_score: 0.7784752666382387
[epoch: 47 -- Lr: [0.00018530201888518417] -- time: 26.460914611816406s]  --- Acc_train: 0.7819408795670509 --- loss_train : 0.07889702525612638 --- Acc_val: 0.777747402952433 --- loss_val : 0.08043241532551579 --- f1_score: 0.7785767044993511
[epoch: 48 -- Lr: [0.00016677181699666576] -- time: 26.568037271499634s]  --- Acc_train: 0.7823205706503855 --- loss_train : 0.07870845231671864 --- Acc_val: 0.7803444505194095 --- loss_val : 0.08022850651317111 --- f1_score: 0.78107953715029
[epoch: 49 -- Lr: [0.00015009463529699917] -- time: 26.50450086593628s]  --- Acc_train: 0.7819408795670509 --- loss_train : 0.07888440400775173 --- Acc_val: 0.7792965190450155 --- loss_val : 0.08035358926975936 --- f1_score: 0.7799728805857823
[epoch: 50 -- Lr: [0.0001350851717672993] -- time: 29.474993228912354s]  --- Acc_train: 0.7822294447903853 --- loss_train : 0.07862871287172717 --- Acc_val: 0.7809823218516494 --- loss_val : 0.08010483284046616 --- f1_score: 0.781682099042875
[epoch: 51 -- Lr: [0.00012157665459056935] -- time: 28.748281955718994s]  --- Acc_train: 0.7827508872114981 --- loss_train : 0.07850049410130043 --- Acc_val: 0.7798432659012211 --- loss_val : 0.08030176677175575 --- f1_score: 0.7805381025496875
[epoch: 52 -- Lr: [0.00010941898913151242] -- time: 27.831675052642822s]  --- Acc_train: 0.7828318879759427 --- loss_train : 0.07852018273571212 --- Acc_val: 0.779114270092947 --- loss_val : 0.08008152228804301 --- f1_score: 0.7799937738150877
[epoch: 53 -- Lr: [9.847709021836118e-05] -- time: 26.966609239578247s]  --- Acc_train: 0.7827559497592759 --- loss_train : 0.07845738226581189 --- Acc_val: 0.7821213778020777 --- loss_val : 0.08006771100208689 --- f1_score: 0.7827899292121032
[epoch: 54 -- Lr: [8.862938119652506e-05] -- time: 27.99777626991272s]  --- Acc_train: 0.7827205119248313 --- loss_train : 0.07847658739772716 --- Acc_val: 0.7818024421359577 --- loss_val : 0.08010589097650185 --- f1_score: 0.7825496603585338
[epoch: 55 -- Lr: [7.976644307687256e-05] -- time: 26.59026026725769s]  --- Acc_train: 0.7827103868292757 --- loss_train : 0.07846645600754013 --- Acc_val: 0.7811190085657007 --- loss_val : 0.08011286098762675 --- f1_score: 0.7818246002014534
[epoch: 56 -- Lr: [7.17897987691853e-05] -- time: 28.78860354423523s]  --- Acc_train: 0.7823661335803856 --- loss_train : 0.0784380388468753 --- Acc_val: 0.7807545106615636 --- loss_val : 0.08043373699022359 --- f1_score: 0.7814622120289908
[epoch: 57 -- Lr: [6.461081889226677e-05] -- time: 31.493401527404785s]  --- Acc_train: 0.7833938307792779 --- loss_train : 0.07830541503322073 --- Acc_val: 0.782941498086386 --- loss_val : 0.08034843263659112 --- f1_score: 0.7834553439966884
[epoch: 58 -- Lr: [5.8149737003040094e-05] -- time: 26.668723106384277s]  --- Acc_train: 0.7827913875937205 --- loss_train : 0.0784323417004371 --- Acc_val: 0.7803444505194095 --- loss_val : 0.08009694234529623 --- f1_score: 0.7810745995050474
[epoch: 59 -- Lr: [5.233476330273609e-05] -- time: 29.1774263381958s]  --- Acc_train: 0.7830850153648325 --- loss_train : 0.07827096617097885 --- Acc_val: 0.7824403134681975 --- loss_val : 0.07999825275623047 --- f1_score: 0.7830760548032145
[epoch: 60 -- Lr: [4.7101286972462485e-05] -- time: 32.45082402229309s]  --- Acc_train: 0.7829938895048322 --- loss_train : 0.0783104632224212 --- Acc_val: 0.7811645708037179 --- loss_val : 0.08003478435774146 --- f1_score: 0.7818352291290731
[epoch: 61 -- Lr: [4.239115827521624e-05] -- time: 27.4023277759552s]  --- Acc_train: 0.7832672670848331 --- loss_train : 0.07812825635721705 --- Acc_val: 0.7824403134681975 --- loss_val : 0.08027589965912754 --- f1_score: 0.7829889071580367
[epoch: 62 -- Lr: [3.8152042447694614e-05] -- time: 26.915764093399048s]  --- Acc_train: 0.7839557735826131 --- loss_train : 0.078070208297566 --- Acc_val: 0.7808911973756151 --- loss_val : 0.07991730786310873 --- f1_score: 0.7816445169037207
[epoch: 63 -- Lr: [3.433683820292515e-05] -- time: 26.735522747039795s]  --- Acc_train: 0.7844468407170593 --- loss_train : 0.07819315067869663 --- Acc_val: 0.7810278840896665 --- loss_val : 0.08003652671417448 --- f1_score: 0.7817152763918207
[epoch: 64 -- Lr: [3.090315438263264e-05] -- time: 27.26438546180725s]  --- Acc_train: 0.7835811450470563 --- loss_train : 0.07817323887644424 --- Acc_val: 0.7813012575177692 --- loss_val : 0.08038496240843254 --- f1_score: 0.7819661518605504
[epoch: 65 -- Lr: [2.7812838944369376e-05] -- time: 27.702404975891113s]  --- Acc_train: 0.7832014539637218 --- loss_train : 0.07823888539469749 --- Acc_val: 0.7820758155640605 --- loss_val : 0.08038321775150532 --- f1_score: 0.7826434613687985
[epoch: 66 -- Lr: [2.5031555049932436e-05] -- time: 27.584677934646606s]  --- Acc_train: 0.7832470168937219 --- loss_train : 0.07813952575415256 --- Acc_val: 0.7813468197557865 --- loss_val : 0.08001007400304103 --- f1_score: 0.7820446333946329
[epoch: 67 -- Lr: [2.2528399544939195e-05] -- time: 32.446089029312134s]  --- Acc_train: 0.7840165241559467 --- loss_train : 0.07813217604998385 --- Acc_val: 0.7807089484235465 --- loss_val : 0.079905068358026 --- f1_score: 0.781439099263224
[epoch: 68 -- Lr: [2.0275559590445276e-05] -- time: 28.88015103340149s]  --- Acc_train: 0.7832520794414998 --- loss_train : 0.07803828771293637 --- Acc_val: 0.7818480043739748 --- loss_val : 0.07997683784694413 --- f1_score: 0.7824900735551892
[epoch: 69 -- Lr: [1.824800363140075e-05] -- time: 26.72633647918701s]  --- Acc_train: 0.7835001442826117 --- loss_train : 0.07815929209404933 --- Acc_val: 0.7813923819938036 --- loss_val : 0.07992905222753062 --- f1_score: 0.7821042268198741
[epoch: 70 -- Lr: [1.6423203268260675e-05] -- time: 27.13291311264038s]  --- Acc_train: 0.7837482091237236 --- loss_train : 0.07813815583044614 --- Acc_val: 0.7808911973756151 --- loss_val : 0.07994014064383347 --- f1_score: 0.7816014652822328
[epoch: 71 -- Lr: [1.4780882941434608e-05] -- time: 26.882445096969604s]  --- Acc_train: 0.7845177163859484 --- loss_train : 0.07793159282137534 --- Acc_val: 0.7804355749954438 --- loss_val : 0.08001358503300394 --- f1_score: 0.7811987490405516
[epoch: 72 -- Lr: [1.3302794647291146e-05] -- time: 27.782644271850586s]  --- Acc_train: 0.7838393349837239 --- loss_train : 0.07804988498025839 --- Acc_val: 0.7806178239475123 --- loss_val : 0.07992606364446511 --- f1_score: 0.781367691143872
[epoch: 73 -- Lr: [1.1972515182562033e-05] -- time: 27.28626585006714s]  --- Acc_train: 0.7838393349837239 --- loss_train : 0.07799022074846373 --- Acc_val: 0.781210133041735 --- loss_val : 0.08004724682516606 --- f1_score: 0.7818850918503093
[epoch: 74 -- Lr: [1.077526366430583e-05] -- time: 26.793872833251953s]  --- Acc_train: 0.7841684005892806 --- loss_train : 0.0780735445934416 --- Acc_val: 0.7810278840896665 --- loss_val : 0.07994276761474786 --- f1_score: 0.7817638989463487
[epoch: 75 -- Lr: [9.697737297875246e-06] -- time: 27.923663854599s]  --- Acc_train: 0.7834697689959449 --- loss_train : 0.07799010499776601 --- Acc_val: 0.7802988882813924 --- loss_val : 0.07996421484738178 --- f1_score: 0.7810513823653356
[epoch: 76 -- Lr: [8.727963568087722e-06] -- time: 27.12443256378174s]  --- Acc_train: 0.7837330214803903 --- loss_train : 0.0779837600215974 --- Acc_val: 0.7817113176599234 --- loss_val : 0.07991638273091588 --- f1_score: 0.7824213354008716
[epoch: 77 -- Lr: [7.85516721127895e-06] -- time: 27.381937265396118s]  --- Acc_train: 0.7843405272137256 --- loss_train : 0.0779944669083946 --- Acc_val: 0.7816657554219063 --- loss_val : 0.0798884922946215 --- f1_score: 0.7823619769635035
[epoch: 78 -- Lr: [7.069650490151056e-06] -- time: 27.479259967803955s]  --- Acc_train: 0.7836115203337232 --- loss_train : 0.07807727861795191 --- Acc_val: 0.7813012575177692 --- loss_val : 0.0799349903506631 --- f1_score: 0.7820366483802343
[epoch: 79 -- Lr: [6.36268544113595e-06] -- time: 28.975045442581177s]  --- Acc_train: 0.7841532129459472 --- loss_train : 0.07805511531740315 --- Acc_val: 0.7818024421359577 --- loss_val : 0.08002584936121072 --- f1_score: 0.7825062605589145
[epoch: 80 -- Lr: [5.726416897022355e-06] -- time: 30.258882522583008s]  --- Acc_train: 0.7835811450470563 --- loss_train : 0.07790971700285415 --- Acc_val: 0.7818024421359577 --- loss_val : 0.08012598699718124 --- f1_score: 0.782446512125808
[epoch: 81 -- Lr: [5.15377520732012e-06] -- time: 28.75775909423828s]  --- Acc_train: 0.783814022244835 --- loss_train : 0.07807598145031137 --- Acc_val: 0.7807089484235465 --- loss_val : 0.07998246089111968 --- f1_score: 0.781442509352073
[epoch: 82 -- Lr: [4.638397686588108e-06] -- time: 27.520233154296875s]  --- Acc_train: 0.7832824547281665 --- loss_train : 0.07800770088168597 --- Acc_val: 0.7814835064698378 --- loss_val : 0.07999587293474328 --- f1_score: 0.7821259252134977
[epoch: 83 -- Lr: [4.174557917929297e-06] -- time: 27.64547872543335s]  --- Acc_train: 0.7840367743470579 --- loss_train : 0.07793896863330688 --- Acc_val: 0.7808000728995809 --- loss_val : 0.07985922381605624 --- f1_score: 0.7815586380062386
[epoch: 84 -- Lr: [3.7571021261363675e-06] -- time: 26.88537621498108s]  --- Acc_train: 0.7834849566392783 --- loss_train : 0.07807106144708015 --- Acc_val: 0.7815290687078549 --- loss_val : 0.07990756828649041 --- f1_score: 0.782230960191484
[epoch: 85 -- Lr: [3.381391913522731e-06] -- time: 27.511013746261597s]  --- Acc_train: 0.7836823960026122 --- loss_train : 0.07801743333701068 --- Acc_val: 0.7802988882813924 --- loss_val : 0.07993953035828118 --- f1_score: 0.7810762524982736
[epoch: 86 -- Lr: [3.0432527221704577e-06] -- time: 26.548562049865723s]  --- Acc_train: 0.7832419543459441 --- loss_train : 0.07808059932904717 --- Acc_val: 0.7813923819938036 --- loss_val : 0.0799234972744528 --- f1_score: 0.7821263576320625
[epoch: 87 -- Lr: [2.7389274499534123e-06] -- time: 26.987187147140503s]  --- Acc_train: 0.7837583342192792 --- loss_train : 0.07793958868702938 --- Acc_val: 0.7814379442318207 --- loss_val : 0.08004019704659128 --- f1_score: 0.7821068527369601
[epoch: 88 -- Lr: [2.465034704958071e-06] -- time: 30.66542387008667s]  --- Acc_train: 0.7837026461937234 --- loss_train : 0.07788460587356633 --- Acc_val: 0.7803900127574267 --- loss_val : 0.07987751492034037 --- f1_score: 0.781166810895185
[epoch: 89 -- Lr: [2.218531234462264e-06] -- time: 33.05915427207947s]  --- Acc_train: 0.7834950817348338 --- loss_train : 0.07787806240375075 --- Acc_val: 0.7815290687078549 --- loss_val : 0.07981620164097084 --- f1_score: 0.7822883134736929
[epoch: 90 -- Lr: [1.9966781110160375e-06] -- time: 28.615684747695923s]  --- Acc_train: 0.7834343311615003 --- loss_train : 0.07793056145621824 --- Acc_val: 0.7810278840896665 --- loss_val : 0.07986439914983257 --- f1_score: 0.7817522476954704
[epoch: 91 -- Lr: [1.797010299914434e-06] -- time: 28.181684255599976s]  --- Acc_train: 0.7842342137103919 --- loss_train : 0.07806601012189936 --- Acc_val: 0.7816201931838892 --- loss_val : 0.07987595201541857 --- f1_score: 0.7823311748826861
[epoch: 92 -- Lr: [1.6173092699229906e-06] -- time: 26.51500105857849s]  --- Acc_train: 0.7839152732003908 --- loss_train : 0.07787104339115426 --- Acc_val: 0.7810278840896665 --- loss_val : 0.07998518662552463 --- f1_score: 0.781719207699481
[epoch: 93 -- Lr: [1.4555783429306915e-06] -- time: 28.234716653823853s]  --- Acc_train: 0.7835203944737228 --- loss_train : 0.0779196149679135 --- Acc_val: 0.7812556952797521 --- loss_val : 0.08000804557487602 --- f1_score: 0.7819886557244717
[epoch: 94 -- Lr: [1.3100205086376223e-06] -- time: 27.19064235687256s]  --- Acc_train: 0.7836722709070567 --- loss_train : 0.078005074347017 --- Acc_val: 0.780845635137598 --- loss_val : 0.07988144905271966 --- f1_score: 0.7815370362712453
[epoch: 95 -- Lr: [1.1790184577738603e-06] -- time: 31.981722116470337s]  --- Acc_train: 0.7840873998248359 --- loss_train : 0.07793297486614836 --- Acc_val: 0.7813468197557865 --- loss_val : 0.07993404114227419 --- f1_score: 0.7821109291845727
[epoch: 96 -- Lr: [1.061116611996474e-06] -- time: 31.899071216583252s]  --- Acc_train: 0.7844063403348369 --- loss_train : 0.07798750053265913 --- Acc_val: 0.7818935666119919 --- loss_val : 0.08007993225771277 --- f1_score: 0.7825524126865844
[epoch: 97 -- Lr: [9.550049507968267e-07] -- time: 27.2368586063385s]  --- Acc_train: 0.78368745855039 --- loss_train : 0.07816734538695529 --- Acc_val: 0.7813012575177692 --- loss_val : 0.07993424016567444 --- f1_score: 0.781981513867936
[epoch: 98 -- Lr: [8.595044557171441e-07] -- time: 26.584189653396606s]  --- Acc_train: 0.7840063990603912 --- loss_train : 0.07789638570810357 --- Acc_val: 0.7814379442318207 --- loss_val : 0.08006087993528244 --- f1_score: 0.7821303995373244
[epoch: 99 -- Lr: [7.735540101454298e-07] -- time: 28.155518531799316s]  --- Acc_train: 0.7837988346015016 --- loss_train : 0.07805353471473714 --- Acc_val: 0.7794332057590669 --- loss_val : 0.07991025185110011 --- f1_score: 0.7802439569797943
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  acc_train ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:    acc_val ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   f1_score ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: loss_train ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   loss_val ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  acc_train 0.78488
wandb:    acc_val 0.78066
wandb:   f1_score 0.78144
wandb: loss_train 0.07798
wandb:   loss_val 0.07989
wandb: 
wandb: üöÄ View run WES_ws_16 at: https://wandb.ai/huyennm/Mutation_Detection_With_CNN%20/runs/pe3y8dwj
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_045652-pe3y8dwj/logs
[epoch: 100 -- Lr: [6.961986091308867e-07] -- time: 32.00709676742554s]  --- Acc_train: 0.7848771572781719 --- loss_train : 0.07798060342282633 --- Acc_val: 0.7806633861855294 --- loss_val : 0.07989152265439387 --- f1_score: 0.7814377060983048
****** Testing model with best checkpoint******
[491. 225.  10.] [597. 283.  16.] [0.82244556 0.795053   0.625     ] 0.8102678571428571
              precision    recall  f1-score   support

           0       0.88      0.82      0.85       597
           1       0.70      0.80      0.74       283
           2       0.56      0.62      0.59        16

    accuracy                           0.81       896
   macro avg       0.71      0.75      0.73       896
weighted avg       0.82      0.81      0.81       896

****** Testing model with last checkpoint******
[480. 231.  10.] [597. 283.  16.] [0.8040201  0.81625442 0.625     ] 0.8046875
              precision    recall  f1-score   support

           0       0.89      0.80      0.85       597
           1       0.68      0.82      0.74       283
           2       0.50      0.62      0.56        16

    accuracy                           0.80       896
   macro avg       0.69      0.75      0.72       896
weighted avg       0.82      0.80      0.81       896

